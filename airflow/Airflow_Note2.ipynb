{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airflow Note2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回顧\n",
    "\n",
    "* 最簡單安裝 \n",
    "> pip install apache-airflow  \n",
    "> pip install \"apache-airflow[crypto, password]\"  \n",
    "    \n",
    "    \n",
    "*  初始化數據庫 `airflow initdb` [必須的步驟]\n",
    "*  啟動web服務器 `airflow webserver -p 8080` [方便可視化管理dag]\n",
    "*  啟動任務 `airflow scheduler` [scheduler啟動後，DAG目錄下的dags就會根據設定的時間定時啟動]\n",
    "*  此外我們還可以直接測試單個DAG，如測試文章末尾的DAG `airflow test ct1 print_date 2016-05-14`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 配置 mysql以啟用 LocalExecutor 和 CeleryExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安裝 MySQL 及設定 root 密碼  \n",
    "\n",
    "> apt-get install mysql-server  \n",
    "\n",
    "調整 MySQL 設定檔\n",
    "\n",
    "> vim /etc/my.cnf：  \n",
    "\n",
    "~~~\n",
    "[client]  \n",
    "default-character-set=utf8  \n",
    "\n",
    "\n",
    "[mysql]\n",
    "default-character-set=utf8\n",
    "\n",
    "[mysqld]\n",
    "collation-server=utf8_general_ci\n",
    "init-connect='SET NAMES utf8'\n",
    "character-set-server = utf8\n",
    "# Recommended in standard MySQL setup\n",
    "sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES,NO_BACKSLASH_ESCAPES  \n",
    "explicit_defaults_for_timestamp = 1\n",
    "~~~\n",
    "\n",
    "**對於MYSQL 大於 5.6**\n",
    "> show global variables like '%timestamp%';  \n",
    "\n",
    "> set global explicit_defaults_for_timestamp = 1;\n",
    "\n",
    "啟動服務:  \n",
    "\n",
    "> service mysql start\n",
    "\n",
    "\n",
    "4.登入 MySQL\n",
    "\n",
    "> mysql -u root -p\n",
    "\n",
    "5.創資料庫 \n",
    "> CREATE DATABASE airflow;  \n",
    "  \n",
    "6.新建用戶`airflow`，密碼為`12345`，該用戶對數據庫`airflow`有完全操作權限\n",
    "> GRANT all privileges on airflow.* TO 'airflow'@'localhost'  IDENTIFIED BY '12345';  \n",
    "> FLUSH PRIVILEGES; \n",
    "\n",
    "7.更改Airflow DB的encode  \n",
    "> ALTER DATABASE `airflow` CHARACTER SET utf8; \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 安裝 airflow mysql: \n",
    "> pip install apache-airflow[mysql]   \n",
    "\n",
    "\n",
    "##### 修改airflow配置文件支持mysql\n",
    "airflow.cfg文件通常在~/airflow目錄下\n",
    "\n",
    "更改DB鏈接: `sql_alchemy_conn = mysql://airflow:12345@localhost/airflow`   \n",
    "對應字段解釋如下： `dialect+driver://username:password@host:port/database` \n",
    "\n",
    "初始化數據庫 `airflow initdb`  \n",
    "\n",
    "初始化數據庫成功後，可進入mysql查看新生成的數據表。  \n",
    "> mysql -u airflow -p 12345   \n",
    "\n",
    "> USE airflow;    \n",
    "\n",
    "> SHOW TABLES;     \n",
    "\n",
    "~~~\n",
    "+-------------------+  \n",
    "| Tables_in_airflow |  \n",
    "+-------------------+\n",
    "| alembic_version   |\n",
    "| chart             |\n",
    "| connection        |\n",
    "| dag               |\n",
    "| dag_pickle        |\n",
    "| dag_run           |\n",
    "| import_error      |\n",
    "| job               |\n",
    "| known_event       |\n",
    "| known_event_type  |\n",
    "| log               |\n",
    "| sla_miss          |\n",
    "| slot_pool         |\n",
    "| task_instance     |\n",
    "| users             |\n",
    "| variable          |\n",
    "| xcom              |\n",
    "+-------------------+\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 配置LocalExecutor  \n",
    "\n",
    "修改airflow配置文件: `airflow.cfg`  \n",
    "* 更改executor為executor = LocalExecutor  \n",
    "\n",
    "測試  \n",
    "* airflow webserver -- debug & "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~  \n",
    "**server_only**  \n",
    "\n",
    "    ps -ef | grep -Ei '(airflow-webserver)' | grep master | awk '{print $2}' | xargs -i kill {}\n",
    "\n",
    "    cd ~/airflow/\n",
    "    nohup airflow webserver >webserver.log 2>&1 &\n",
    "\n",
    "**resart_all**  \n",
    "\n",
    "    ps -ef | grep -Ei 'airflow' | grep -v 'grep' | awk '{print $2}' | xargs -i kill {}\n",
    "\n",
    "    cd ~/airflow/\n",
    "    nohup airflow webserver -p 8080 >>webserver.log 2>&1 &\n",
    "    #nohup airflow worker >>worker.log 2>&1 &\n",
    "    nohup airflow scheduler >>scheduler.log 2>&1 &\n",
    "\n",
    "**start_all**\n",
    "\n",
    "    cd ~/airflow/\n",
    "    nohup airflow webserver -p 8080 >>webserver.log 2>&1 &\n",
    "    #nohup airflow worker >>worker.log 2>&1 &\n",
    "    nohup airflow scheduler >>scheduler.log 2>&1 &  \n",
    "    \n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### airflow.cfg 其它配置\n",
    "\n",
    "`dags_folder`  \n",
    "\n",
    "\n",
    "##### dags_folder目錄支持子目錄和軟連接，因此不同的dag可以分門別類的存儲起來。  \n",
    "\n",
    "\n",
    "* 設置郵件發送服務\n",
    "~~~\n",
    "smtp_host = smtp.163.com\n",
    "smtp_starttls = True\n",
    "smtp_ssl = False\n",
    "smtp_user = username@163.com\n",
    "smtp_port = 25\n",
    "smtp_password = userpasswd\n",
    "smtp_mail_from = username@163.com\n",
    "~~~\n",
    "\n",
    "* 多用戶登錄設置(似乎只有CeleryExecutor支持)\n",
    "\n",
    "  - 修改airflow.cfg中的下面3行配置  \n",
    "\n",
    "~~~\n",
    "authenticate = True\n",
    "auth_backend = airflow.contrib.auth.backends.password_auth\n",
    "filter_by_owner = True\n",
    "~~~   \n",
    "\n",
    "    - 增加一個用戶(在airflow所在服務器的python下運行)\n",
    "~~~\n",
    "import airflow\n",
    "from airflow import models,   settings\n",
    "from airflow.contrib.auth.backends.password_auth import PasswordUser\n",
    "user = PasswordUser(models.User())\n",
    "user.username = 'ehbio'\n",
    "user.email = 'mail@ehbio.com'\n",
    "user.password = 'ehbio'\n",
    "session = settings.Session()\n",
    "session.add(user)\n",
    "session.commit()\n",
    "session.close()\n",
    "exit()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### TASK  \n",
    "\n",
    "*參數解釋*\n",
    "\n",
    "* depends_on_past  \n",
    "\n",
    "\n",
    "Airflow assumes idempotent tasks that operate on immutable data chunks.   \n",
    "It also assumes that all task instance (each task for each schedule) needs to run.  \n",
    "\n",
    "If your tasks need to be executed sequentially, you need to tell Airflow:   \n",
    "use the `depends_on_past=Trueflag` on the tasks that require sequential execution.)  \n",
    "\n",
    "\n",
    "\n",
    "如果在TASK本該運行卻沒有運行時，或者設置的interval為@once時，推薦使用depends_on_past=False。   \n",
    "在運行dag時，有時會出現，明明上游任務已經運行結束，下游任務卻沒有啟動，整個dag就卡住了。   \n",
    "這時設置depends_on_past=False可以解決這類問題。   \n",
    "\n",
    "~~~\n",
    "default_args = {\n",
    "    'owner': 'airflow',          \n",
    "    'start_date': datetime(2016, 5, 29, 8, 30), \n",
    "    #'email': ['chentong_biology@163.com'],\n",
    "    #'email_on_failure': False, \n",
    "    #'email_on_retry': False, \n",
    "    'depends_on_past': False, \n",
    "    'retries': 1, \n",
    "    'retry_delay': timedelta(minutes=5), \n",
    "    #'queue': 'bash_queue',\n",
    "    #'pool': 'backfill', \n",
    "    #'priority_weight': 10, \n",
    "\t  #'end_date': datetime(2016, 5, 29, 11, 30), \n",
    "}  \n",
    "~~~\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* timestamp in format like 2016-01-01T00:03:00\n",
    "\n",
    "* Task中調用的命令出錯後需要在網站Graph view中點擊run手動重啟。為了方便任務修改後的順利運行，有個折衷的方法是：\n",
    "\n",
    "  * 設置 email_on_retry: True\n",
    "  * 設置較長的retry_delay，方便在收到郵件後，能有時間做出處理\n",
    "  * 然後再修改為較短的retry_delay，方便快速啟動  \n",
    "    \n",
    "   \n",
    "* 在特定情況下，修改後的一天，為了避免當前日期之前任務的運行，可以使用回填填補特定時間段的任務\n",
    "> airflow backfill -s START -e END --mark_success DAG_ID    \n",
    "\n",
    "\n",
    "* 對於不想要被 backfill 和 startdate 坑 --> prevent airflow from backfilling dag runs\n",
    "> catchup=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "####  airflow- 外部檔案\n",
    "\n",
    "* 可以在 web 上 admin->Variables 添加 key與value\n",
    "  之後便可以透過參數 Variable.get(key)讀取\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### airflow 管理帳號\n",
    "\n",
    "\n",
    "\n",
    "> pip install flask-bcrypt  \n",
    "\n",
    "~~~\n",
    "$ python\n",
    "Python 2.7.9 (default, Feb 10 2015, 03:28:08)\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> import airflow\n",
    ">>> from airflow import models, settings\n",
    ">>> from airflow.contrib.auth.backends.password_auth import PasswordUser\n",
    ">>> user = PasswordUser(models.User())\n",
    ">>> user.username = 'new_user_name'\n",
    ">>> user.email = 'new_user_email@example.com'\n",
    ">>> user.password = 'set_the_password'\n",
    ">>> session = settings.Session()\n",
    ">>> session.add(user)\n",
    ">>> session.commit()\n",
    ">>> session.close()\n",
    ">>> exit()\n",
    "~~~\n",
    "\n",
    "然後透過 web 更改 user權限給剛剛創立的帳號(admin->users)\n",
    "\n",
    "最後Check the following in your airflow.cfg file:  \n",
    "[webserver]  \n",
    "authenticate = True  \n",
    "auth_backend = airflow.contrib.auth.backends.password_auth  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "\n",
    "### SUBDAG 用法  \n",
    "\n",
    "* 可以在其他檔案寫入:  \n",
    "\n",
    "~~~\n",
    "from airflow.models import DAG\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "def func():\n",
    "    ....\n",
    "\n",
    "\n",
    "def subdag(parent_dag_name, child_dag_name, args):\n",
    "    dag_subdag = DAG(  \n",
    "        \n",
    "        #這裡的 child_dag_name 要跟之後的task_id 一樣\n",
    "        #-------------------------------------------------------------\n",
    "        dag_id='%s.%s' % (parent_dag_name, child_dag_name),\n",
    "        #-------------------------------------------------------------\n",
    "        default_args=args,\n",
    "        schedule_interval=\"@daily\",\n",
    "    )\n",
    "\n",
    " test1 = PythonOperator(  \n",
    "        task_id='sleep_for_1',  \n",
    "        python_callable=func,  \n",
    "        op_args = [param],  \n",
    "        #op_kwargs={'random_base': float(i) / 10},  \n",
    "        dag=dag_subdag,  \n",
    "    )\n",
    "\n",
    " test2 = PythonOperator(  \n",
    "        task_id='sleep_for_2',  \n",
    "        python_callable=func,  \n",
    "        op_args = [param],  \n",
    "        #op_kwargs={'random_base': float(i) / 10},  \n",
    "        dag=dag_subdag,  \n",
    "    )\n",
    "\n",
    "    #------- 這裡要回傳DAG ------------------\n",
    "    return dag_subdag\n",
    "    #---------------------------------------\n",
    "~~~\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 主要構建DAG 檔案的地方\n",
    "\n",
    "\n",
    "~~~ \n",
    "import airflow\n",
    "#-----------------這裡import剛剛的檔案----------------------\n",
    "from airflow.example_dags.subdags.subdag import subdag\n",
    "#----------------------------------------------------------\n",
    "from airflow.models import DAG\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.operators.subdag_operator import SubDagOperator\n",
    "\n",
    "\n",
    "DAG_NAME = 'example_subdag_operator'\n",
    "\n",
    "args = {\n",
    "    'owner': 'airflow',\n",
    "    'start_date': airflow.utils.dates.days_ago(2),\n",
    "}\n",
    "\n",
    "with DAG( dag_id=DAG_NAME, default_args=args, schedule_interval=\"@once\",) as dag:\n",
    "\n",
    "    start = DummyOperator(\n",
    "        task_id='start',\n",
    "        default_args=args,\n",
    "        dag=dag,\n",
    "    )\n",
    "#----------------這裡使用SubDagOperator----------------\n",
    "    section_1 = SubDagOperator(\n",
    "        task_id='section-1',\n",
    "        subdag=subdag(DAG_NAME, 'section-1', args),\n",
    "        default_args=args,\n",
    "        dag=dag,\n",
    "    )\n",
    "#------------------------------------------------------\n",
    "    some_other_task = DummyOperator(\n",
    "        task_id='some-other-task',\n",
    "        default_args=args,\n",
    "        dag=dag,\n",
    "    )\n",
    "    \n",
    "    \n",
    "#----------------這裡使用SubDagOperator----------------\n",
    "    section_2 = SubDagOperator(\n",
    "        task_id='section-2',\n",
    "        subdag=subdag(DAG_NAME, 'section-2', args),\n",
    "        default_args=args,\n",
    "        dag=dag,\n",
    "    )\n",
    "#------------------------------------------------------\n",
    "    end = DummyOperator(\n",
    "        task_id='end',\n",
    "        default_args=args,\n",
    "        dag=dag,\n",
    "    )\n",
    "\n",
    "\n",
    "~~~\n",
    "start >> section_1 >> some_other_task >> section_2 >> end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
